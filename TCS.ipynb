{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jeShN74PLqit"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "def create_knowledge_base(pdf_paths):\n",
        "    # Load and split documents\n",
        "    documents = []\n",
        "    for path in pdf_paths:\n",
        "        loader = PyPDFLoader(path)\n",
        "        documents.extend(loader.load())\n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=1000,\n",
        "        chunk_overlap=200\n",
        "    )\n",
        "    splits = text_splitter.split_documents(documents)\n",
        "\n",
        "    # Create vector store\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "    vectorstore = Chroma.from_documents(\n",
        "        documents=splits,\n",
        "        embedding=embeddings,\n",
        "        persist_directory=\"./insurance_db\"\n",
        "    )\n",
        "    return vectorstore"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "\n",
        "class InsuranceChatbot:\n",
        "    def __init__(self, vectorstore):\n",
        "        self.llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
        "        self.memory = ConversationBufferMemory(\n",
        "            memory_key=\"chat_history\",\n",
        "            return_messages=True\n",
        "        )\n",
        "        self.qa_chain = ConversationalRetrievalChain.from_llm(\n",
        "            self.llm,\n",
        "            vectorstore.as_retriever(),\n",
        "            memory=self.memory\n",
        "        )\n",
        "\n",
        "    def respond(self, query):\n",
        "        try:\n",
        "            result = self.qa_chain({\"question\": query})\n",
        "            return result[\"answer\"]\n",
        "        except Exception as e:\n",
        "            return (\"I'm having trouble answering that. \"\n",
        "                   \"Would you like to speak with a human agent?\")"
      ],
      "metadata": {
        "id": "H3pCMcsNLtqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "from streamlit_chat import message\n",
        "\n",
        "def main():\n",
        "    st.title(\"Insurance Policy Information Chatbot\")\n",
        "\n",
        "    if 'chatbot' not in st.session_state:\n",
        "        # Initialize with pre-created knowledge base\n",
        "        vectorstore = Chroma(\n",
        "            persist_directory=\"./insurance_db\",\n",
        "            embedding_function=OpenAIEmbeddings()\n",
        "        )\n",
        "        st.session_state.chatbot = InsuranceChatbot(vectorstore)\n",
        "\n",
        "    if 'generated' not in st.session_state:\n",
        "        st.session_state.generated = []\n",
        "    if 'past' not in st.session_state:\n",
        "        st.session_state.past = []\n",
        "\n",
        "    # Chat input\n",
        "    user_input = st.text_input(\"Ask about insurance policies:\", key=\"input\")\n",
        "\n",
        "    if user_input:\n",
        "        output = st.session_state.chatbot.respond(user_input)\n",
        "        st.session_state.past.append(user_input)\n",
        "        st.session_state.generated.append(output)\n",
        "\n",
        "    # Display conversation\n",
        "    if st.session_state.generated:\n",
        "        for i in range(len(st.session_state.generated)):\n",
        "            message(st.session_state.past[i], is_user=True, key=f\"{i}_user\")\n",
        "            message(st.session_state.generated[i], key=f\"{i}\")\n",
        "\n",
        "    # Human agent fallback\n",
        "    if st.session_state.generated and \"human agent\" in st.session_state.generated[-1].lower():\n",
        "        st.warning(\"Please contact our customer service at 1-800-INSURANCE for further assistance.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "xobfU6hTLwCG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}